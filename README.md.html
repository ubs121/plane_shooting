<!DOCTYPE html>
<html>
  <head>
      <meta charset="utf-8" />
      <title>README</title>
      <style>.markdown-preview:not([data-use-github-style]) { padding: 2em; font-size: 1.2em; color: rgb(85, 85, 85); overflow: auto; background-color: rgb(255, 255, 255); }
.markdown-preview:not([data-use-github-style]) > :first-child { margin-top: 0px; }
.markdown-preview:not([data-use-github-style]) h1, .markdown-preview:not([data-use-github-style]) h2, .markdown-preview:not([data-use-github-style]) h3, .markdown-preview:not([data-use-github-style]) h4, .markdown-preview:not([data-use-github-style]) h5, .markdown-preview:not([data-use-github-style]) h6 { line-height: 1.2; margin-top: 1.5em; margin-bottom: 0.5em; color: rgb(3, 3, 3); }
.markdown-preview:not([data-use-github-style]) h1 { font-size: 2.4em; font-weight: 300; }
.markdown-preview:not([data-use-github-style]) h2 { font-size: 1.8em; font-weight: 400; }
.markdown-preview:not([data-use-github-style]) h3 { font-size: 1.5em; font-weight: 500; }
.markdown-preview:not([data-use-github-style]) h4 { font-size: 1.2em; font-weight: 600; }
.markdown-preview:not([data-use-github-style]) h5 { font-size: 1.1em; font-weight: 600; }
.markdown-preview:not([data-use-github-style]) h6 { font-size: 1em; font-weight: 600; }
.markdown-preview:not([data-use-github-style]) strong { color: rgb(3, 3, 3); }
.markdown-preview:not([data-use-github-style]) del { color: rgb(126, 126, 126); }
.markdown-preview:not([data-use-github-style]) a, .markdown-preview:not([data-use-github-style]) a code { color: rgb(0, 0, 0); }
.markdown-preview:not([data-use-github-style]) img { max-width: 100%; }
.markdown-preview:not([data-use-github-style]) > p { margin-top: 0px; margin-bottom: 1.5em; }
.markdown-preview:not([data-use-github-style]) > ul, .markdown-preview:not([data-use-github-style]) > ol { margin-bottom: 1.5em; }
.markdown-preview:not([data-use-github-style]) blockquote { margin: 1.5em 0px; font-size: inherit; color: rgb(126, 126, 126); border-color: rgb(214, 214, 214); border-width: 4px; }
.markdown-preview:not([data-use-github-style]) hr { margin: 3em 0px; border-top-width: 2px; border-top-style: dashed; border-top-color: rgb(214, 214, 214); background: none; }
.markdown-preview:not([data-use-github-style]) table { margin: 1.5em 0px; }
.markdown-preview:not([data-use-github-style]) th { color: rgb(3, 3, 3); }
.markdown-preview:not([data-use-github-style]) th, .markdown-preview:not([data-use-github-style]) td { padding: 0.66em 1em; border: 1px solid rgb(214, 214, 214); }
.markdown-preview:not([data-use-github-style]) code { color: rgb(3, 3, 3); background-color: rgb(240, 240, 240); }
.markdown-preview:not([data-use-github-style]) pre.editor-colors { margin: 1.5em 0px; padding: 1em; font-size: 0.92em; border-radius: 3px; background-color: rgb(245, 245, 245); }
.markdown-preview:not([data-use-github-style]) kbd { color: rgb(3, 3, 3); border-width: 1px 1px 2px; border-style: solid; border-color: rgb(214, 214, 214) rgb(214, 214, 214) rgb(199, 199, 199); background-color: rgb(240, 240, 240); }
.markdown-preview[data-use-github-style] { font-family: 'Helvetica Neue', Helvetica, 'Segoe UI', Arial, freesans, sans-serif; line-height: 1.6; word-wrap: break-word; padding: 30px; font-size: 16px; color: rgb(51, 51, 51); overflow: scroll; background-color: rgb(255, 255, 255); }
.markdown-preview[data-use-github-style] > :first-child { margin-top: 0px !important; }
.markdown-preview[data-use-github-style] > :last-child { margin-bottom: 0px !important; }
.markdown-preview[data-use-github-style] a:not([href]) { color: inherit; text-decoration: none; }
.markdown-preview[data-use-github-style] .absent { color: rgb(204, 0, 0); }
.markdown-preview[data-use-github-style] .anchor { position: absolute; top: 0px; left: 0px; display: block; padding-right: 6px; padding-left: 30px; margin-left: -30px; }
.markdown-preview[data-use-github-style] .anchor:focus { outline: none; }
.markdown-preview[data-use-github-style] h1, .markdown-preview[data-use-github-style] h2, .markdown-preview[data-use-github-style] h3, .markdown-preview[data-use-github-style] h4, .markdown-preview[data-use-github-style] h5, .markdown-preview[data-use-github-style] h6 { position: relative; margin-top: 1em; margin-bottom: 16px; font-weight: bold; line-height: 1.4; }
.markdown-preview[data-use-github-style] h1 .octicon-link, .markdown-preview[data-use-github-style] h2 .octicon-link, .markdown-preview[data-use-github-style] h3 .octicon-link, .markdown-preview[data-use-github-style] h4 .octicon-link, .markdown-preview[data-use-github-style] h5 .octicon-link, .markdown-preview[data-use-github-style] h6 .octicon-link { display: none; color: rgb(0, 0, 0); vertical-align: middle; }
.markdown-preview[data-use-github-style] h1:hover .anchor, .markdown-preview[data-use-github-style] h2:hover .anchor, .markdown-preview[data-use-github-style] h3:hover .anchor, .markdown-preview[data-use-github-style] h4:hover .anchor, .markdown-preview[data-use-github-style] h5:hover .anchor, .markdown-preview[data-use-github-style] h6:hover .anchor { padding-left: 8px; margin-left: -30px; text-decoration: none; }
.markdown-preview[data-use-github-style] h1:hover .anchor .octicon-link, .markdown-preview[data-use-github-style] h2:hover .anchor .octicon-link, .markdown-preview[data-use-github-style] h3:hover .anchor .octicon-link, .markdown-preview[data-use-github-style] h4:hover .anchor .octicon-link, .markdown-preview[data-use-github-style] h5:hover .anchor .octicon-link, .markdown-preview[data-use-github-style] h6:hover .anchor .octicon-link { display: inline-block; }
.markdown-preview[data-use-github-style] h1 tt, .markdown-preview[data-use-github-style] h2 tt, .markdown-preview[data-use-github-style] h3 tt, .markdown-preview[data-use-github-style] h4 tt, .markdown-preview[data-use-github-style] h5 tt, .markdown-preview[data-use-github-style] h6 tt, .markdown-preview[data-use-github-style] h1 code, .markdown-preview[data-use-github-style] h2 code, .markdown-preview[data-use-github-style] h3 code, .markdown-preview[data-use-github-style] h4 code, .markdown-preview[data-use-github-style] h5 code, .markdown-preview[data-use-github-style] h6 code { font-size: inherit; }
.markdown-preview[data-use-github-style] h1 { padding-bottom: 0.3em; font-size: 2.25em; line-height: 1.2; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); }
.markdown-preview[data-use-github-style] h1 .anchor { line-height: 1; }
.markdown-preview[data-use-github-style] h2 { padding-bottom: 0.3em; font-size: 1.75em; line-height: 1.225; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: rgb(238, 238, 238); }
.markdown-preview[data-use-github-style] h2 .anchor { line-height: 1; }
.markdown-preview[data-use-github-style] h3 { font-size: 1.5em; line-height: 1.43; }
.markdown-preview[data-use-github-style] h3 .anchor { line-height: 1.2; }
.markdown-preview[data-use-github-style] h4 { font-size: 1.25em; }
.markdown-preview[data-use-github-style] h4 .anchor { line-height: 1.2; }
.markdown-preview[data-use-github-style] h5 { font-size: 1em; }
.markdown-preview[data-use-github-style] h5 .anchor { line-height: 1.1; }
.markdown-preview[data-use-github-style] h6 { font-size: 1em; color: rgb(119, 119, 119); }
.markdown-preview[data-use-github-style] h6 .anchor { line-height: 1.1; }
.markdown-preview[data-use-github-style] p, .markdown-preview[data-use-github-style] blockquote, .markdown-preview[data-use-github-style] ul, .markdown-preview[data-use-github-style] ol, .markdown-preview[data-use-github-style] dl, .markdown-preview[data-use-github-style] table, .markdown-preview[data-use-github-style] pre { margin-top: 0px; margin-bottom: 16px; }
.markdown-preview[data-use-github-style] hr { height: 4px; padding: 0px; margin: 16px 0px; border: 0px none; background-color: rgb(231, 231, 231); }
.markdown-preview[data-use-github-style] ul, .markdown-preview[data-use-github-style] ol { padding-left: 2em; }
.markdown-preview[data-use-github-style] ul.no-list, .markdown-preview[data-use-github-style] ol.no-list { padding: 0px; list-style-type: none; }
.markdown-preview[data-use-github-style] ul ul, .markdown-preview[data-use-github-style] ul ol, .markdown-preview[data-use-github-style] ol ol, .markdown-preview[data-use-github-style] ol ul { margin-top: 0px; margin-bottom: 0px; }
.markdown-preview[data-use-github-style] li > p { margin-top: 16px; }
.markdown-preview[data-use-github-style] dl { padding: 0px; }
.markdown-preview[data-use-github-style] dl dt { padding: 0px; margin-top: 16px; font-size: 1em; font-style: italic; font-weight: bold; }
.markdown-preview[data-use-github-style] dl dd { padding: 0px 16px; margin-bottom: 16px; }
.markdown-preview[data-use-github-style] blockquote { padding: 0px 15px; color: rgb(119, 119, 119); border-left-width: 4px; border-left-style: solid; border-left-color: rgb(221, 221, 221); }
.markdown-preview[data-use-github-style] blockquote > :first-child { margin-top: 0px; }
.markdown-preview[data-use-github-style] blockquote > :last-child { margin-bottom: 0px; }
.markdown-preview[data-use-github-style] table { display: block; width: 100%; overflow: auto; word-break: keep-all; }
.markdown-preview[data-use-github-style] table th { font-weight: bold; }
.markdown-preview[data-use-github-style] table th, .markdown-preview[data-use-github-style] table td { padding: 6px 13px; border: 1px solid rgb(221, 221, 221); }
.markdown-preview[data-use-github-style] table tr { border-top-width: 1px; border-top-style: solid; border-top-color: rgb(204, 204, 204); background-color: rgb(255, 255, 255); }
.markdown-preview[data-use-github-style] table tr:nth-child(2n) { background-color: rgb(248, 248, 248); }
.markdown-preview[data-use-github-style] img { max-width: 100%; box-sizing: border-box; }
.markdown-preview[data-use-github-style] .emoji { max-width: none; }
.markdown-preview[data-use-github-style] span.frame { display: block; overflow: hidden; }
.markdown-preview[data-use-github-style] span.frame > span { display: block; float: left; width: auto; padding: 7px; margin: 13px 0px 0px; overflow: hidden; border: 1px solid rgb(221, 221, 221); }
.markdown-preview[data-use-github-style] span.frame span img { display: block; float: left; }
.markdown-preview[data-use-github-style] span.frame span span { display: block; padding: 5px 0px 0px; clear: both; color: rgb(51, 51, 51); }
.markdown-preview[data-use-github-style] span.align-center { display: block; overflow: hidden; clear: both; }
.markdown-preview[data-use-github-style] span.align-center > span { display: block; margin: 13px auto 0px; overflow: hidden; text-align: center; }
.markdown-preview[data-use-github-style] span.align-center span img { margin: 0px auto; text-align: center; }
.markdown-preview[data-use-github-style] span.align-right { display: block; overflow: hidden; clear: both; }
.markdown-preview[data-use-github-style] span.align-right > span { display: block; margin: 13px 0px 0px; overflow: hidden; text-align: right; }
.markdown-preview[data-use-github-style] span.align-right span img { margin: 0px; text-align: right; }
.markdown-preview[data-use-github-style] span.float-left { display: block; float: left; margin-right: 13px; overflow: hidden; }
.markdown-preview[data-use-github-style] span.float-left span { margin: 13px 0px 0px; }
.markdown-preview[data-use-github-style] span.float-right { display: block; float: right; margin-left: 13px; overflow: hidden; }
.markdown-preview[data-use-github-style] span.float-right > span { display: block; margin: 13px auto 0px; overflow: hidden; text-align: right; }
.markdown-preview[data-use-github-style] code, .markdown-preview[data-use-github-style] tt { padding: 0.2em 0px; margin: 0px; font-size: 85%; border-radius: 3px; background-color: rgba(0, 0, 0, 0.0392157); }
.markdown-preview[data-use-github-style] code::before, .markdown-preview[data-use-github-style] tt::before, .markdown-preview[data-use-github-style] code::after, .markdown-preview[data-use-github-style] tt::after { letter-spacing: -0.2em; content: " "; }
.markdown-preview[data-use-github-style] code br, .markdown-preview[data-use-github-style] tt br { display: none; }
.markdown-preview[data-use-github-style] del code { text-decoration: inherit; }
.markdown-preview[data-use-github-style] pre > code { padding: 0px; margin: 0px; font-size: 100%; word-break: normal; white-space: pre; border: 0px; background: transparent; }
.markdown-preview[data-use-github-style] .highlight { margin-bottom: 16px; }
.markdown-preview[data-use-github-style] .highlight pre, .markdown-preview[data-use-github-style] pre { padding: 16px; overflow: auto; font-size: 85%; line-height: 1.45; border-radius: 3px; background-color: rgb(247, 247, 247); }
.markdown-preview[data-use-github-style] .highlight pre { margin-bottom: 0px; word-break: normal; }
.markdown-preview[data-use-github-style] pre { word-wrap: normal; }
.markdown-preview[data-use-github-style] pre code, .markdown-preview[data-use-github-style] pre tt { display: inline; max-width: initial; padding: 0px; margin: 0px; overflow: initial; line-height: inherit; word-wrap: normal; border: 0px; background-color: transparent; }
.markdown-preview[data-use-github-style] pre code::before, .markdown-preview[data-use-github-style] pre tt::before, .markdown-preview[data-use-github-style] pre code::after, .markdown-preview[data-use-github-style] pre tt::after { content: normal; }
.markdown-preview[data-use-github-style] kbd { display: inline-block; padding: 3px 5px; font-size: 11px; line-height: 10px; color: rgb(85, 85, 85); vertical-align: middle; border-style: solid; border-width: 1px; border-color: rgb(204, 204, 204) rgb(204, 204, 204) rgb(187, 187, 187); border-radius: 3px; box-shadow: rgb(187, 187, 187) 0px -1px 0px inset; background-color: rgb(252, 252, 252); }
.markdown-preview[data-use-github-style] a { color: rgb(51, 122, 183); }
.markdown-preview[data-use-github-style] code { color: inherit; }
.markdown-preview[data-use-github-style] pre.editor-colors { padding: 0.8em 1em; margin-bottom: 1em; font-size: 0.85em; border-radius: 4px; overflow: auto; }
.scrollbars-visible-always .markdown-preview pre.editor-colors::shadow .vertical-scrollbar, .scrollbars-visible-always .markdown-preview pre.editor-colors::shadow .horizontal-scrollbar { visibility: hidden; }
.scrollbars-visible-always .markdown-preview pre.editor-colors:hover::shadow .vertical-scrollbar, .scrollbars-visible-always .markdown-preview pre.editor-colors:hover::shadow .horizontal-scrollbar { visibility: visible; }
.bracket-matcher .region {
  border-bottom: 1px dotted lime;
  position: absolute;
}

.spell-check-misspelling .region {
  border-bottom: 2px dotted rgba(255, 51, 51, 0.75);
}
.spell-check-corrections {
  width: 25em !important;
}

pre.editor-colors,
.host {
  background-color: #ffffff;
  color: #555555;
}
pre.editor-colors .invisible-character,
.host .invisible-character {
  color: rgba(85, 85, 85, 0.2);
}
pre.editor-colors .indent-guide,
.host .indent-guide {
  color: rgba(85, 85, 85, 0.2);
}
pre.editor-colors .wrap-guide,
.host .wrap-guide {
  background-color: rgba(85, 85, 85, 0.2);
}
pre.editor-colors .gutter,
.host .gutter {
  color: #555555;
  background: #ffffff;
}
pre.editor-colors .gutter .line-number.folded,
.host .gutter .line-number.folded,
pre.editor-colors .gutter .line-number:after,
.host .gutter .line-number:after,
pre.editor-colors .fold-marker:after,
.host .fold-marker:after {
  color: #e87b00;
}
pre.editor-colors .invisible,
.host .invisible {
  color: #555;
}
pre.editor-colors .selection .region,
.host .selection .region {
  background-color: #e1e1e1;
}
pre.editor-colors.is-focused .cursor,
.host.is-focused .cursor {
  border-color: #000000;
}
pre.editor-colors.is-focused .selection .region,
.host.is-focused .selection .region {
  background-color: #afc4da;
}
pre.editor-colors.is-focused .line-number.cursor-line-no-selection,
.host.is-focused .line-number.cursor-line-no-selection,
pre.editor-colors.is-focused .line.cursor-line,
.host.is-focused .line.cursor-line {
  background-color: rgba(255, 255, 134, 0.34);
}
pre.editor-colors .source.gfm,
.host .source.gfm {
  color: #444;
}
pre.editor-colors .gfm .markup.heading,
.host .gfm .markup.heading {
  color: #111;
}
pre.editor-colors .gfm .link,
.host .gfm .link {
  color: #888;
}
pre.editor-colors .gfm .variable.list,
.host .gfm .variable.list {
  color: #888;
}
pre.editor-colors .markdown .paragraph,
.host .markdown .paragraph {
  color: #444;
}
pre.editor-colors .markdown .heading,
.host .markdown .heading {
  color: #111;
}
pre.editor-colors .markdown .link,
.host .markdown .link {
  color: #888;
}
pre.editor-colors .markdown .link .string,
.host .markdown .link .string {
  color: #888;
}
.host(.is-focused) .cursor {
  border-color: #000000;
}
.host(.is-focused) .selection .region {
  background-color: #afc4da;
}
.host(.is-focused) .line-number.cursor-line-no-selection,
.host(.is-focused) .line.cursor-line {
  background-color: rgba(255, 255, 134, 0.34);
}
.comment {
  color: #999988;
  font-style: italic;
}
.string {
  color: #D14;
}
.string .source,
.string .meta.embedded.line {
  color: #5A5A5A;
}
.string .punctuation.section.embedded {
  color: #920B2D;
}
.string .punctuation.section.embedded .source {
  color: #920B2D;
}
.constant.numeric {
  color: #D14;
}
.constant.language {
  color: #606aa1;
}
.constant.character,
.constant.other {
  color: #606aa1;
}
.constant.symbol {
  color: #990073;
}
.constant.numeric.line-number.find-in-files .match {
  color: rgba(143, 190, 0, 0.63);
}
.variable {
  color: #008080;
}
.variable.parameter {
  color: #606aa1;
}
.keyword {
  color: #222;
  font-weight: bold;
}
.keyword.unit {
  color: #445588;
}
.keyword.special-method {
  color: #0086B3;
}
.storage {
  color: #222;
}
.storage.type {
  color: #222;
}
.entity.name.class {
  text-decoration: underline;
  color: #606aa1;
}
.entity.other.inherited-class {
  text-decoration: underline;
  color: #606aa1;
}
.entity.name.function {
  color: #900;
}
.entity.name.tag {
  color: #008080;
}
.entity.other.attribute-name {
  color: #458;
  font-weight: bold;
}
.entity.name.filename.find-in-files {
  color: #E6DB74;
}
.support.constant,
.support.function,
.support.type {
  color: #458;
}
.support.class {
  color: #008080;
}
.invalid {
  color: #F8F8F0;
  background-color: #00A8C6;
}
.invalid.deprecated {
  color: #F8F8F0;
  background-color: #8FBE00;
}
.meta.structure.dictionary.json > .string.quoted.double.json,
.meta.structure.dictionary.json > .string.quoted.double.json .punctuation.string {
  color: #000080;
}
.meta.structure.dictionary.value.json > .string.quoted.double.json {
  color: #d14;
}
.meta.diff,
.meta.diff.header {
  color: #75715E;
}
.css.support.property-name {
  font-weight: bold;
  color: #333;
}
.css.constant {
  color: #099;
}
.bracket-matcher .region {
  background-color: #C9C9C9;
  opacity: .7;
  border-bottom: 0 none;
}
</style>
  </head>
  <body class='markdown-preview' data-use-github-style><h1 id="capstone-project-plane-shooting">Capstone Project - Plane shooting</h1>
<h2 id="machine-learning-engineer-nanodegree">Machine Learning Engineer Nanodegree</h2>
<p>Uuganbayar Sukhbaatar<br>August 29th, 2016</p>
<h2 id="i-definition">I. Definition</h2>
<h3 id="project-overview">Project Overview</h3>
<p>This is a pencil and paper game similar to the <a href="https://en.wikipedia.org/wiki/Battleship_game">Battleship game</a>. We used to play this game during school days.</p>
<p>The game is played by 2 players on four grids, two for each player. The grids are 10×10 square – and the individual squares in the grid are identified by row and column number. On one grid the player arranges ships and records the shots by the opponent. On the other grid the player records their own shots.</p>
<p>Before play begins, each player secretly arranges their planes on their primary grid, usually 2-3 planes. Each plane occupies a number of consecutive squares on the grid, arranged either horizontally or vertically.</p>
<p>One player tells the coordinates for shot, and the other give a feedback whether the player has hit or missed the plane. The best shooter who shot all planes of the opponent will win the game.</p>
<h3 id="problem-statement">Problem Statement</h3>
<p>Human player secretly arranges a plane with the following figure on a grid with size of 10x10, let&#39;s say it an environment. You have to develop an <code>agent</code> that is capable to learn how to shoot the plane in this environment.</p>
<p><em>Figure-1: The shape of plane, and the environment</em></p>
<p><img src="/Users/ub/src/plane_shooting/plane1.png" alt="">  <img src="/Users/ub/src/plane_shooting/NEWS.png" style="height:5em"></p>
<p>The human player gives a feedback with letter <code>H</code> for head shot, <code>B</code> for body shot and <code>M</code> for miss (see the figure above).</p>
<p>Using this feedback the agent have to find the head of the plane with minimum possible shots. The agent must learn optimal technique using Machine Learning, and be able to compete with a human player. The Reinforcement Learning is recommended one, but any Machine Learning technique or combination of them are accepted.</p>
<h3 id="metrics">Metrics</h3>
<p>The agent&#39;s goal is to find the plane head with minimum possible shots.  So how many shots are required to destroy any plane? I couldn&#39;t tell exact number, but I have some reasonable metrics.</p>
<p>To measure the performance of the agent, I have chosen the average number of shots until the head is found. This will be a main factor to indicate the performance of the agent.</p>
<p>The average number of shots is calculated as the following.</p>
<pre class="editor-colors lang-text"><div class="line"><span class="text plain"><span>&nbsp;&nbsp;</span><span class="meta paragraph text"><span>Average&nbsp;shot&nbsp;=&nbsp;totals&nbsp;shots&nbsp;/&nbsp;the&nbsp;number&nbsp;of&nbsp;play</span></span></span></div></pre><h2 id="ii-analysis">II. Analysis</h2>
<h3 id="data-exploration">Data Exploration</h3>
<p>There is no existing dataset for this problem. But there is some input, one is a hint.</p>
<p>In order to minimize shots, a hint for next possible head locations is given to the agent. The agent must learn from this hint, and learn to select the best guess for head shot.</p>
<p>As I know, there are some well known tactics for the best guess. I didn&#39;t explore all best tactics, the agent might found those best tactics during learning process.</p>
<p>The below is shown two of them.</p>
<p><strong> Sample 1: A body shot </strong></p>
<p>For example, if got a body shot &#39;B&#39; on location (4,5), then after this shot the hint will look like the following. There are 32 possible head locations after the body shot at (4,5).</p>
<p>  <em>Figure-2: A body shot and next possible head shots</em></p>
<p>  <img src="/Users/ub/src/plane_shooting/shot_B.png" alt="shot B"></p>
<p>Furthermore from this visualization of head distribution, we could see that the intersected squares (with tick borders) are the most efficient shots. Specially the square <code>(3,4)</code>, <code>(5,4)</code>, <code>(3,6)</code> and <code>(5,6)</code> are the most efficient locations to try. By shooting at these squares the agent will be rewarded as one of the following:</p>
<ul>
<li><p>Could win the game by just hitting a head, because these four locations are possible head locations.</p>
</li>
<li><p>Could be a body shot, for example at <code>(3,4)</code>. If so the next possible head locations will be 3 times less at least.</p>
<p><em>Figure-3: Two body shots</em></p>
<p><img src="/Users/ub/src/plane_shooting/shot_BB.png" alt="shot BB"></p>
</li>
<li><p>Could be a miss. Even in this case the agent will get a benefit, because the next possible head locations will be reduced by 6.</p>
<p><em>Figure-4: A missed shot and after a body shot</em></p>
<p><img src="/Users/ub/src/plane_shooting/shot_BM.png" alt="shot BM"></p>
</li>
</ul>
<p><strong> Sample 2: A missed shot </strong></p>
<p>If the agent missed at <code>(2,2)</code>, then it still has to learn something from this shot, because this shot will reduce the next possible heads somehow. In the below figure, white squares are non-head coordinates after this missed shot, so the agent will skip these squares for the next shot.</p>
<p><em>Figure-5: A missed shot on the corner</em></p>
<p><img src="/Users/ub/src/plane_shooting/shot_M.png" alt="shot M"></p>
<p>Then, the agent may choose the median points from the hint for the next shot, but the closest one from the last shot. These shots will open more &quot;white&quot; squares than others, so the agent will be rewarded more.</p>
<p><em>Figure-6: Effective shot points after a missed shot</em></p>
<p><img src="/Users/ub/src/plane_shooting/shot_M_.png" alt="shot M_"></p>
<h3 id="algorithms-and-techniques">Algorithms and Techniques</h3>
<p>This is a simple guessing game, but it has some degree of complexity similar to other board games like Chess and Go.</p>
<p>The problem could be solved by using the Reinforcement Learning (RL) approach, more specifically using Q-Learning method. The ultimate goal is to make an agent able to play against real human and let it learn all best tactics. The Q-Learning has been proven that for any finite Markov decision process, so using this method the agent eventually find an optimal policy.</p>
<p>The idea is to reward every efficient shot. How efficient is measured by the reduction of unknown area on every shot. A big reduction will be rewarded more, a little reduction will be rewarded less. So it will lead to the minimal shots and to the optimal tactics.</p>
<p>Also could be some punishment, for example we could punish the agent if it shoot at same point repeatedly.</p>
<p>The agent could use &quot;all random guess&quot; tactic. But it will not succeed, even it may be worse than the simple plain 100 shots. So the agent has to learn some best practices under some policy.</p>
<p>The best tactic is to explore the grid and shrink the blue area as much as possible while seeking the plane head.</p>
<p>With this idea and enough number of training, I think, the agent could &#39;learn&#39; how to shoot efficiently.</p>
<p><strong> Parameters for RL </strong></p>
<p>Here is the main parameters for RL:</p>
<ul>
<li><p><em>States</em>: If we count every square values on the grid, there could be 3^100 states for this game. 3 is the number of shot marks per square, these are &#39;B&#39;, &#39;M&#39; and empty, 100 is the number of squares. This is a huge number and takes tremendous amount of time to train the agent. Anyway we will use a grid with the shot marks as a state, because it represents the current state the best.</p>
</li>
<li><p><em>Actions</em>: There are 100 actions, each action represents every square of the grid. Luckily we will use hints to limit the number of actions. So it will be fewer and fewer &#39;state-action&#39; combinations after each shot.</p>
</li>
<li><p><em>Reward</em>: Finding a optimal reward policy is the one important part of this solution. Reward policy which I found the most optimal is: If the agent hit the head of plane, then it will be rewarded by 100 points. In other cases, the reward will be equal to the reduction size of the blue area (head hints). It won&#39;t exceed than 100, that is why the maximum reward is 100.</p>
<p>General reward formula is:</p>
<pre class="editor-colors lang-text"><div class="line"><span class="text plain"><span class="meta paragraph text"><span>reward&nbsp;=&nbsp;len(hint_old)&nbsp;-&nbsp;len(hint_new)</span></span></span></div></pre><p>For example, in case of the <code>Sample 1</code> of the section &#39;Data Exploration&#39;, by shooting at <code>(3,4)</code>, the agent will be rewarded by score 22, because before the shot the length of hint was 32, after the shot it become 10, so 32 - 10 = 22. So the shot was efficient that much in that particular state.</p>
</li>
<li><p><em>Punishment</em>: The agent should avoid repeated shots at same location. It&#39;s extremely useless and stupid action, so we could punish the agent by -1000 (almost never do it again). Also we could punish the agent if it shot at different location than a suggested hint.</p>
</li>
<li><p><em>Alpha</em>: alpha 0.1 is suggested value for a stochastic problem</p>
</li>
<li><p><em>Gamma</em>: It could be 2.0. So the agent will focus on current rewards. I think a current reward policy is efficient enough to lead the agent into correct way.</p>
</li>
<li><p><em>Epsilon</em>: Since this is a stochastic type of problem, I set the epsilon to 0.5. So the agent is allowed to make random shots with 50% probability. In other 50%, it must use it&#39;s past experience.</p>
</li>
</ul>
<h3 id="benchmark">Benchmark</h3>
<p>In worst case the agent could find the head with 100 shots, which means it has to hit every square on the grid. But our agent has to be smarter than this.</p>
<p>It&#39;s possible to find some part of the plane with 10 shots at maximum. Because the plane occupies 1/10 size of space on the board. Only thing is to keep correct amount of gap between shots to cover all area.</p>
<p>Once the agent hit on the body of the plane it should be easy to guess the head. Usually 2-4 shots needed to find the head after body shot. So in total, 14 shots should be enough to destroy any plane.</p>
<p>From my experience, it is possible to find the head of plane with 9 shots on average. So this could be a guideline value for benchmark. Some lucky human players could find the head with 5-6 shots.</p>
<p>There are 168 plane layouts in total. So we will benchmark the agent for all these possible layouts.</p>
<p>Also you could design a certain scenario like as the chess game and could check the actions of the agent in this scenario.</p>
<h2 id="iii-methodology">III. Methodology</h2>
<h3 id="data-preprocessing">Data Preprocessing</h3>
<p>There is no data pre-processing is required for this problem.</p>
<p>But after the problem is solved we could use the trained dataset for a real game (against real human).</p>
<h3 id="implementation">Implementation</h3>
<p>The implementation consists from 3 code sections: environment, agent and simulation modules.</p>
<p><strong> The environment module </strong></p>
<p> The environment implementation was the most important part of the problem. It contains the grid and plane. This is also a controller module, that controls the game using the reward and punishment approach.</p>
<p> The most important methods are:</p>
<ul>
<li><p><code>new_game()</code> - it prepares for a new game, initialize the grid, cleans data, layout the plane  etc.</p>
</li>
<li><p><code>shoot()</code> - it applies a shot in the environment and calculates the reward for that shot. The following code section calculates the reward.</p>
<pre class="editor-colors lang-python"><div class="line"><span class="source python"><span>hint_old</span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span class="meta function-call python"><span class="support function builtin python"><span>len</span></span><span class="punctuation definition arguments begin python"><span>(</span></span><span class="meta function-call arguments python"><span class="variable language self python"><span>self</span></span><span>.</span><span>hints</span></span><span class="punctuation definition arguments end python"><span>)</span></span></span></span></div><div class="line"><span class="source python"><span>&nbsp;</span></span></div><div class="line"><span class="source python"><span class="keyword control conditional python"><span>if</span></span><span>&nbsp;</span><span>shot_resp</span><span>&nbsp;</span><span class="keyword operator comparison python"><span>==</span></span><span>&nbsp;</span><span class="string quoted single single-line python"><span class="punctuation definition string begin python"><span>&#39;</span></span><span>H</span><span class="punctuation definition string end python"><span>&#39;</span></span></span><span>:&nbsp;</span><span class="comment line number-sign python"><span class="punctuation definition comment python"><span>#</span></span><span>&nbsp;head&nbsp;shot</span><span>&nbsp;</span></span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>reward</span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span class="constant numeric float python"><span>100.0</span></span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="meta item-access python"><span class="variable language self python"><span>self</span></span><span>.</span><span>board</span><span class="punctuation definition arguments begin python"><span>[</span></span><span class="meta item-access arguments python"><span class="meta item-access python"><span>shot</span><span class="punctuation definition arguments begin python"><span>[</span></span><span class="meta item-access arguments python"><span class="constant numeric integer decimal python"><span>1</span></span></span><span class="punctuation definition arguments end python"><span>]</span></span></span></span><span class="punctuation definition arguments end python"><span>]</span></span></span><span class="meta structure list python"><span class="punctuation definition list begin python"><span>[</span></span><span class="meta structure list item python"><span class="meta item-access python"><span>shot</span><span class="punctuation definition arguments begin python"><span>[</span></span><span class="meta item-access arguments python"><span class="constant numeric integer decimal python"><span>0</span></span></span><span class="punctuation definition arguments end python"><span>]</span></span></span></span><span class="punctuation definition list end python"><span>]</span></span></span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span>shot_resp</span></span></div><div class="line"><span class="source python"><span class="keyword control conditional python"><span>else</span></span><span>:</span></span></div><div class="line"><span class="source python"><span class="punctuation whitespace comment leading python"><span>&nbsp;&nbsp;&nbsp;&nbsp;</span></span><span class="comment line number-sign python"><span class="punctuation definition comment python"><span>#</span></span><span>&nbsp;&nbsp;punish&nbsp;by&nbsp;-10000.0&nbsp;for&nbsp;repeated&nbsp;shot</span><span>&nbsp;</span></span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="keyword control conditional python"><span>if</span></span><span>&nbsp;</span><span class="meta item-access python"><span class="variable language self python"><span>self</span></span><span>.</span><span>board</span><span class="punctuation definition arguments begin python"><span>[</span></span><span class="meta item-access arguments python"><span class="meta item-access python"><span>shot</span><span class="punctuation definition arguments begin python"><span>[</span></span><span class="meta item-access arguments python"><span class="constant numeric integer decimal python"><span>1</span></span></span><span class="punctuation definition arguments end python"><span>]</span></span></span></span><span class="punctuation definition arguments end python"><span>]</span></span></span><span class="meta structure list python"><span class="punctuation definition list begin python"><span>[</span></span><span class="meta structure list item python"><span class="meta item-access python"><span>shot</span><span class="punctuation definition arguments begin python"><span>[</span></span><span class="meta item-access arguments python"><span class="constant numeric integer decimal python"><span>0</span></span></span><span class="punctuation definition arguments end python"><span>]</span></span></span></span><span class="punctuation definition list end python"><span>]</span></span></span><span>&nbsp;</span><span class="keyword operator comparison python"><span>!=</span></span><span>&nbsp;</span><span class="string quoted single single-line python"><span class="punctuation definition string begin python"><span>&#39;</span></span><span>&nbsp;</span><span class="punctuation definition string end python"><span>&#39;</span></span></span><span>:</span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>reward</span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span class="keyword operator arithmetic python"><span>-</span></span><span class="constant numeric float python"><span>1000.0</span></span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="keyword control conditional python"><span>else</span></span><span>:</span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="meta function-call python"><span class="variable language self python"><span>self</span></span><span>.</span><span>_update_hints</span><span class="punctuation definition arguments begin python"><span>(</span></span><span class="meta function-call arguments python"><span>shot</span><span>,&nbsp;</span><span>shot_resp</span></span><span class="punctuation definition arguments end python"><span>)</span></span></span></span></div><div class="line"><span class="source python"><span class="punctuation whitespace comment leading python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></span><span class="comment line number-sign python"><span class="punctuation definition comment python"><span>#</span></span><span>&nbsp;reward&nbsp;amount</span><span>&nbsp;</span></span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>reward</span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span>hint_old</span><span>&nbsp;</span><span class="keyword operator arithmetic python"><span>-</span></span><span>&nbsp;</span><span class="meta function-call python"><span class="support function builtin python"><span>len</span></span><span class="punctuation definition arguments begin python"><span>(</span></span><span class="meta function-call arguments python"><span class="variable language self python"><span>self</span></span><span>.</span><span>hints</span></span><span class="punctuation definition arguments end python"><span>)</span></span></span></span></div></pre>
</li>
<li><p>get_hints() - gives a hint of possible head locations, hint will be updated after every shot</p>
</li>
</ul>
<p>There are other utility methods.</p>
<ul>
<li><p><code>random_plane()</code> - creates a random positioned plane.</p>
</li>
<li><p><code>valid()</code> - checks if a given head and position is valid</p>
</li>
<li><p><code>show()</code> - displays the environment on the screen</p>
</li>
</ul>
<p><strong> The agent module </strong></p>
<p>This is a student, our agent, that learns how to shoot. This agent is capable to shoot and can learn based on the feedback.</p>
<ul>
<li><p><code>next_shoot()</code> - gives a shot</p>
</li>
<li><p><code>learn()</code> - learns from the feedback</p>
</li>
<li><p><code>build_state()</code> - forms a current state</p>
</li>
</ul>
<p>The <code>next_shoot</code> method gives the next shot from the agent and it will be applied in the environment.</p>
<pre class="editor-colors lang-python"><div class="line"><span class="source python"><span class="meta function python"><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="storage type function python"><span>def</span></span><span>&nbsp;</span><span class="entity name function python"><span>next_shoot</span></span><span class="punctuation definition parameters begin python"><span>(</span></span><span class="meta function parameters python"><span class="variable parameter function python"><span>self</span></span></span><span class="punctuation definition parameters end python"><span>)</span></span><span class="punctuation section function begin python"><span>:</span></span></span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="variable language self python"><span>self</span></span><span>.</span><span>state</span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span class="meta function-call python"><span class="variable language self python"><span>self</span></span><span>.</span><span>build_state</span><span class="punctuation definition arguments begin python"><span>(</span></span><span class="punctuation definition arguments end python"><span>)</span></span></span></span></div><div class="line"><span class="source python"><span>&nbsp;</span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>shot</span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span class="constant numeric integer decimal python"><span>0</span></span></span></div><div class="line"><span class="source python"><span>&nbsp;</span></span></div><div class="line"><span class="source python"><span class="punctuation whitespace comment leading python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></span><span class="comment line number-sign python"><span class="punctuation definition comment python"><span>#</span></span><span>&nbsp;branch&nbsp;according&nbsp;to&nbsp;the&nbsp;exploration&nbsp;factor</span><span>&nbsp;</span></span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="keyword control conditional python"><span>if</span></span><span>&nbsp;</span><span class="meta function-call python"><span>random</span><span>.</span><span>random</span><span class="punctuation definition arguments begin python"><span>(</span></span><span class="punctuation definition arguments end python"><span>)</span></span></span><span>&nbsp;</span><span class="keyword operator comparison python"><span>&lt;</span></span><span>&nbsp;</span><span class="variable language self python"><span>self</span></span><span>.</span><span>epsilon</span><span>:</span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>shot</span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span class="meta function-call python"><span>random</span><span>.</span><span>choice</span><span class="punctuation definition arguments begin python"><span>(</span></span><span class="meta function-call arguments python"><span class="variable language self python"><span>self</span></span><span>.</span><span>actions</span></span><span class="punctuation definition arguments end python"><span>)</span></span></span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="keyword control conditional python"><span>else</span></span><span>:</span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>sa_Q_values</span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span class="meta structure list python"><span class="punctuation definition list begin python"><span>[</span></span><span class="meta structure list item python"><span class="meta function-call python"><span class="variable language self python"><span>self</span></span><span>.</span><span>q</span><span>.</span><span>get</span><span class="punctuation definition arguments begin python"><span>(</span></span><span class="meta function-call arguments python"><span>(</span><span class="variable language self python"><span>self</span></span><span>.</span><span>state</span><span>,&nbsp;</span><span>a</span><span>)</span><span>,&nbsp;</span><span class="constant numeric float python"><span>0.0</span></span></span><span class="punctuation definition arguments end python"><span>)</span></span></span><span>&nbsp;</span><span class="keyword control repeat python"><span>for</span></span><span>&nbsp;</span><span>a</span><span>&nbsp;</span><span class="keyword operator logical python"><span>in</span></span><span>&nbsp;</span><span class="variable language self python"><span>self</span></span><span>.</span><span>actions</span></span><span class="punctuation definition list end python"><span>]</span></span></span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>sa_max</span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span class="meta function-call python"><span class="support function builtin python"><span>max</span></span><span class="punctuation definition arguments begin python"><span>(</span></span><span class="meta function-call arguments python"><span>sa_Q_values</span></span><span class="punctuation definition arguments end python"><span>)</span></span></span></span></div><div class="line"><span class="source python"><span>&nbsp;</span></span></div><div class="line"><span class="source python"><span class="punctuation whitespace comment leading python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></span><span class="comment line number-sign python"><span class="punctuation definition comment python"><span>#</span></span><span>&nbsp;select&nbsp;an&nbsp;action&nbsp;with&nbsp;maximum&nbsp;Q&nbsp;value</span><span>&nbsp;</span></span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>sa_max_indexes</span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span class="meta structure list python"><span class="punctuation definition list begin python"><span>[</span></span><span class="meta structure list item python"><span>i</span><span>&nbsp;</span><span class="keyword control repeat python"><span>for</span></span><span>&nbsp;</span><span>i</span><span>&nbsp;</span><span class="keyword operator logical python"><span>in</span></span><span>&nbsp;</span><span class="meta function-call python"><span class="support function builtin python"><span>range</span></span><span class="punctuation definition arguments begin python"><span>(</span></span><span class="meta function-call arguments python"><span class="meta function-call python"><span class="support function builtin python"><span>len</span></span><span class="punctuation definition arguments begin python"><span>(</span></span><span class="meta function-call arguments python"><span class="variable language self python"><span>self</span></span><span>.</span><span>actions</span></span><span class="punctuation definition arguments end python"><span>)</span></span></span></span><span class="punctuation definition arguments end python"><span>)</span></span></span></span></span></span></div><div class="line"><span class="source python"><span class="meta structure list python"><span class="meta structure list item python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="keyword control conditional python"><span>if</span></span><span>&nbsp;</span><span class="meta item-access python"><span>sa_Q_values</span><span class="punctuation definition arguments begin python"><span>[</span></span><span class="meta item-access arguments python"><span>i</span></span><span class="punctuation definition arguments end python"><span>]</span></span></span><span>&nbsp;</span><span class="keyword operator comparison python"><span>==</span></span><span>&nbsp;</span><span>sa_max</span></span><span class="punctuation definition list end python"><span>]</span></span></span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>i</span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span class="meta function-call python"><span>random</span><span>.</span><span>choice</span><span class="punctuation definition arguments begin python"><span>(</span></span><span class="meta function-call arguments python"><span>sa_max_indexes</span></span><span class="punctuation definition arguments end python"><span>)</span></span></span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>shot</span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span class="meta item-access python"><span class="variable language self python"><span>self</span></span><span>.</span><span>actions</span><span class="punctuation definition arguments begin python"><span>[</span></span><span class="meta item-access arguments python"><span>i</span></span><span class="punctuation definition arguments end python"><span>]</span></span></span></span></div><div class="line"><span class="source python"><span>&nbsp;</span></span></div><div class="line"><span class="source python"><span class="punctuation whitespace comment leading python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></span><span class="comment line number-sign python"><span class="punctuation definition comment python"><span>#</span></span><span>&nbsp;(x,&nbsp;y)&nbsp;хэлбэрт&nbsp;оруулах</span><span>&nbsp;</span></span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>y</span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span>shot</span><span>&nbsp;</span><span class="keyword operator arithmetic python"><span>/</span></span><span>&nbsp;</span><span class="variable language self python"><span>self</span></span><span>.</span><span>env</span><span>.</span><span>size</span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>x</span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span>shot</span><span>&nbsp;</span><span class="keyword operator arithmetic python"><span>%</span></span><span>&nbsp;</span><span class="variable language self python"><span>self</span></span><span>.</span><span>env</span><span>.</span><span>size</span></span></div><div class="line"><span class="source python"><span>&nbsp;</span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="keyword control statement python"><span>return</span></span><span>&nbsp;</span><span>(</span><span>x</span><span>,&nbsp;</span><span>y</span><span>)</span></span></div></pre>
<p>After every shot the agent learns using <code>learn()</code> method.</p>
<pre class="editor-colors lang-python"><div class="line"><span class="source python"><span class="meta function python"><span>&nbsp;&nbsp;</span><span class="storage type function python"><span>def</span></span><span>&nbsp;</span><span class="entity name function python"><span>learn</span></span><span class="punctuation definition parameters begin python"><span>(</span></span><span class="meta function parameters python"><span class="variable parameter function python"><span>self</span></span><span class="punctuation separator parameters python"><span>,</span></span><span>&nbsp;</span><span class="variable parameter function python"><span>state1</span></span><span class="punctuation separator parameters python"><span>,</span></span><span>&nbsp;</span><span class="variable parameter function python"><span>action1</span></span><span class="punctuation separator parameters python"><span>,</span></span><span>&nbsp;</span><span class="variable parameter function python"><span>reward1</span></span><span class="punctuation separator parameters python"><span>,</span></span><span>&nbsp;</span><span class="variable parameter function python"><span>state2</span></span></span><span class="punctuation definition parameters end python"><span>)</span></span><span class="punctuation section function begin python"><span>:</span></span></span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="keyword control conditional python"><span>if</span></span><span>&nbsp;</span><span>state1</span><span>&nbsp;</span><span class="keyword operator comparison python"><span>==</span></span><span>&nbsp;</span><span class="constant language python"><span>None</span></span><span>&nbsp;</span><span class="keyword operator logical python"><span>or</span></span><span>&nbsp;</span><span class="meta function-call python"><span class="support function builtin python"><span>len</span></span><span class="punctuation definition arguments begin python"><span>(</span></span><span class="meta function-call arguments python"><span class="variable language self python"><span>self</span></span><span>.</span><span>actions</span></span><span class="punctuation definition arguments end python"><span>)</span></span></span><span>&nbsp;</span><span class="keyword operator comparison python"><span>==</span></span><span>&nbsp;</span><span class="constant numeric integer decimal python"><span>0</span></span><span>:</span></span></div><div class="line"><span class="source python"><span class="punctuation whitespace comment leading python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></span><span class="comment line number-sign python"><span class="punctuation definition comment python"><span>#</span></span><span>&nbsp;no&nbsp;previuos&nbsp;state</span><span>&nbsp;</span></span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="keyword control statement python"><span>return</span></span></span></div><div class="line"><span class="source python"><span>&nbsp;</span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>sa1</span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span class="meta function-call python"><span class="variable language self python"><span>self</span></span><span>.</span><span>q</span><span>.</span><span>get</span><span class="punctuation definition arguments begin python"><span>(</span></span><span class="meta function-call arguments python"><span>(</span><span>state1</span><span>,&nbsp;</span><span>action1</span><span>)</span><span>,&nbsp;</span><span class="constant numeric float python"><span>0.0</span></span></span><span class="punctuation definition arguments end python"><span>)</span></span></span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>sa2_maxQ</span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span class="meta function-call python"><span class="support function builtin python"><span>max</span></span><span class="punctuation definition arguments begin python"><span>(</span></span><span class="meta function-call arguments python"><span class="meta structure list python"><span class="punctuation definition list begin python"><span>[</span></span><span class="meta structure list item python"><span class="meta function-call python"><span class="variable language self python"><span>self</span></span><span>.</span><span>q</span><span>.</span><span>get</span><span class="punctuation definition arguments begin python"><span>(</span></span><span class="meta function-call arguments python"><span>(</span><span>state2</span><span>,&nbsp;</span><span>a</span><span>)</span><span>,&nbsp;</span><span class="constant numeric float python"><span>0.0</span></span></span><span class="punctuation definition arguments end python"><span>)</span></span></span><span>&nbsp;</span><span class="keyword control repeat python"><span>for</span></span><span>&nbsp;</span><span>a</span><span>&nbsp;</span><span class="keyword operator logical python"><span>in</span></span><span>&nbsp;</span><span class="variable language self python"><span>self</span></span><span>.</span><span>actions</span></span><span class="punctuation definition list end python"><span>]</span></span></span></span><span class="punctuation definition arguments end python"><span>)</span></span></span></span></div><div class="line"><span class="source python"><span>&nbsp;</span></span></div><div class="line"><span class="source python"><span class="punctuation whitespace comment leading python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></span><span class="comment line number-sign python"><span class="punctuation definition comment python"><span>#</span></span><span>&nbsp;Q&nbsp;learning&nbsp;formula:&nbsp;Q(s,a)&nbsp;&lt;-&nbsp;Q(s,a)+alpha[r+&nbsp;gamma*&nbsp;max&nbsp;Q(s&#39;,a&#39;)-Q(s,a)]</span><span>&nbsp;</span></span></span></div><div class="line"><span class="source python"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="meta item-access python"><span class="variable language self python"><span>self</span></span><span>.</span><span>q</span><span class="punctuation definition arguments begin python"><span>[</span></span><span class="meta item-access arguments python"><span>(</span><span>state1</span><span>,&nbsp;</span><span>action1</span><span>)</span></span><span class="punctuation definition arguments end python"><span>]</span></span></span><span>&nbsp;</span><span class="keyword operator assignment python"><span>=</span></span><span>&nbsp;</span><span>sa1</span><span>&nbsp;</span><span class="keyword operator arithmetic python"><span>+</span></span><span>&nbsp;</span><span class="variable language self python"><span>self</span></span><span>.</span><span>alpha</span><span>&nbsp;</span><span class="keyword operator arithmetic python"><span>*</span></span><span>&nbsp;</span><span>(</span><span>reward1</span><span>&nbsp;</span><span class="keyword operator arithmetic python"><span>+</span></span><span>&nbsp;</span><span class="variable language self python"><span>self</span></span><span>.</span><span>gamma</span><span class="keyword operator arithmetic python"><span>*</span></span><span>sa2_maxQ</span><span>&nbsp;</span><span class="keyword operator arithmetic python"><span>-</span></span><span>&nbsp;</span><span>sa1</span><span>)</span></span></div></pre>
<p><strong> The simulator </strong></p>
<p>This module simulates a human player and playes with the agent. It is designed to train the agent and check its performance according to the metrics.</p>
<p>There are 168 variants of the plane. The simulator plays all these variants with the agent, and it does 500 trials for one layout. So it will be 168*500 trials in total.</p>
<h3 id="refinement">Refinement</h3>
<p>I did several experiments on the parameters of Q-Learning.  </p>
<p>I tried other reward policy for the agent. That policy was like: &quot;100 points for head shot, 10 points for body shot, -1 points for missed shot&quot;. But this policy didn&#39;t perform well. Finally have chosen the policy mentioned in the section &quot;Algorithms and Techniques&quot;.</p>
<p>Gamma was set to 2.0. So the agent is more focused on current rewards.</p>
<p>Also I did some test on the epsilon parameter. The agent was performing poorly when epsilon is higher than 0.7, which means mostly random actions were chosen. 0.5 was the best optimal value for the epsilon parameter, also it&#39;s good for exploration.</p>
<table>
<thead>
<tr>
<th></th>
<th>Reward</th>
<th>Gamma</th>
<th>Epsilon</th>
<th>Result (Average shots)</th>
</tr>
</thead>
<tbody>
<tr>
<td>The first version/policy</td>
<td>100 points for head shot, 10 points for body shot, -1 for missed shot</td>
<td>0.7 (long-term high reward)</td>
<td>0.8</td>
<td><code>9.01</code></td>
</tr>
<tr>
<td>Second policy</td>
<td>Equal to the reduction of unknown area</td>
<td>0.2 (current reward)</td>
<td>0.5</td>
<td><code>8.89</code></td>
</tr>
</tbody>
</table>
<h2 id="iv-results">IV. Results</h2>
<p>The final parameters of the agent.</p>
<table>
<thead>
<tr>
<th>Q-Learning parameter</th>
<th>Optimal value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Alpha</td>
<td>0.1</td>
</tr>
<tr>
<td>Gamma</td>
<td>0.2</td>
</tr>
<tr>
<td>Epsilon</td>
<td>0.5</td>
</tr>
<tr>
<td>Reward policy</td>
<td>Equal to the reduction of unknown area</td>
</tr>
</tbody>
</table>
<p>In this configuration, the agent is tested on 168*500 trials. The average shot until head is found was 8.9, this is acceptable result, I think.</p>
<h2 id="v-conclusion">V. Conclusion</h2>
<h3 id="free-form-visualization">Free form visualization</h3>
<p>The shot distribution for particular layout was interesting to me. So I wanted to create some visualization using shot distribution after every simulation.</p>
<p>The following picture shows how the agent sees the plane layout after 100 trials.</p>
<p><strong>Sample 1:</strong></p>
<p>A plane that South headed at (7, 7):</p>
<p><em>Figure-6: Visualization of shot distribution after 100 trials</em></p>
<p><img src="/Users/ub/src/plane_shooting/viz1.png" alt="viz1"></p>
<p>From this visualization we could see the colors, which represents a density of shots at that particular square. The dark blue parts are head and body squares, and lighter area is less or non-related squares to the plane.</p>
<p>It may be a blurred vision, but somehow it shows the agent&#39;s rough &quot;understanding&quot; about that particular layout.</p>
<p>In the picture above you could see that the plane is headed to the South and located at square (7,7).</p>
<p><strong>Sample 2:</strong></p>
<p>A plane that East headed at (8, 7):</p>
<p><em>Figure-7: Another visualization</em></p>
<p><img src="/Users/ub/src/plane_shooting/viz2.png" alt="viz2"></p>
<p> It&#39;s a plane with East head and located at square (8, 7).</p>
<h3 id="reflection">Reflection</h3>
<p>I wanted to solve this problem using Q-Learning algorithm from the beginning, because I had some thoughts:</p>
<ul>
<li>&quot;Could the agent find all best shooting tactics ? Q-Learning might be a perfect answer to find this&quot;</li>
<li>&quot;Could the agent play against an experienced human player ?&quot;</li>
</ul>
<p>I played with my wife, and tried to remember the game tactics and rules. We used to play this game during school days, usually during recess time. Another goal was to discuss and identify key points of the game, according to the Q-Learning approach.</p>
<p>I decided to simplify the game, and changed few things:</p>
<ul>
<li>Use one plane only. Usually we play with 3 planes for real game.</li>
<li>Design an agent that capable to play with human, but in one direction only. At the beginning, I was thinking about an interactive game, bi-directional. Then decided to focus on the core logic of the game, more than a &quot;real playable game&quot;.</li>
</ul>
<p>This is a board game with size 10x10, so it was obvious there will be huge number of state-actions in Q-Learning. The perfect agent must learn all those state-action combinations, which is 3^100 (approx. 5.1537752e+47) states and 100 actions. It&#39;s a huge value, 5.1537752e+49. To memorize this amount of state-actions I might need a lot computing power. So decided to use a hint approach. And the agent must learn to select a best action within the hint. This was the most important and interesting point of the problem.</p>
<p>Finding a good rewarding mechanism was also really challenging. There are 2 requirements on the rewarding policy:</p>
<ul>
<li>it must guide the agent in a correct way, lead to choose the best action</li>
<li>it must lead to the minimal shots</li>
</ul>
<p>I changed the rewarding policy twice, and selected better one.</p>
<p>After key decisions are made, I started writing the environment code (Environment class). This code was the key part of the solution. I did some unit tests on the Plane and Environment classes during the implementation.</p>
<p>After the environment code, I wrote an agent code. The agent implementation was very simple and straightforward, because I re-used some source codes from the former project.</p>
<p>This simulator code was also simple and straightforward. It just loops over all possible variants of the plane, and initiates a play with the agent.
Later, I decided to add some measurement and visualization into the simulator.</p>
<h3 id="improvement">Improvement</h3>
<p>Still there is a room for improvement.</p>
<p>One problem is it takes long time to learn all possible state-actions. It takes 20 minutes to train all layouts, in case of 500 trials per layout. It means we have to wait for 20 minutes if we want to play with the agent on real game. Besides, it learns  only some part of all state-actions. I hope those learnt with 500 trials are the most important combinations, but not sure. To check this we have to prepare some test scenarios like chess game and check the agent for that scenario.</p>
<p>Anyway, we could reduce the training time. One idea is we could divide the game into two phases: one is before a body shot, another phase is after a body shot. The reason is to reduce the number of states. We will have fewer states instead of 3^100 states.</p>
<p>And then, in the first phase, we may not use the Reinforcement Learning, instead we could use some statistics or classification algorithms from the Machine Learning. For the second phase we could use Q Learning as solved before.</p>
<p>Also we could reduce possible actions, specially in the phase two.</p>
<p>Another idea is we could use pre-learned dataset on every run. Then the agent will learn cumulatively.</p></body>
</html>
